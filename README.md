## **Genetic Embeddings: Gerando Embeddings de texto com Algoritmos Evolutivos (EA)**
### SSC0713 - Sistemas Evolutivos Aplicados √† Rob√≥tica
---
* **Docente:** Eduardo do Valle Sim√µes
* **Alunos:** Pedro Henrique de Sousa Prestes (15507819)
---
## üöÄ Introdu√ß√£o
A ideia desse trabalho nasceu da possibilidade de aplicar **Algoritmos Evolutivos/Gen√©ticos (EA/GA/AE/AG)** ao campo do **Processamento de Linguagem Natural (PLN)** inicialmente na previs√£o de palavras de palavras em frases e ap√≥s isso, na gera√ß√£o de *embeddings* de texto, comparando a t√©cnicas bem consolidadas com redes neurais como o **Word2Vec**.

## üìö Metodologia
Inicialmente, foi feito um script simples em Python chamado `prever_palavras.py`, onde o Algoritmo Evolutivo tenta prever a probabilidade da pr√≥xima palavra em uma dada frase, no caso, **"o gato comeu o rato"**, pela simplicidade da implementa√ß√£o, o AG consegue prever bem at√© a √∫ltima palavra (que n√£o √© avaliada propriamente).

Ap√≥s isso, surge a ideia de gerar embeddings com AG, a implementa√ß√£o √© feita no arquivo `embeddings_evolutivos.ipynb`, mais detalhes da sua implementa√ß√£o est√£o ao decorrer do notebook.

## üí° Conclus√£o
Algoritmos Evolutivos podem performar bem em textos com vocabul√°rio pequeno, mas n√£o det√©m o desempenho e muito menos a efici√™ncia do uso de t√©cnicas como Word2Vec, aprendendo principalmente padr√µes sint√°ticos ao inv√©s da sem√¢ntica e decaindo cada vez mais para textos grandes e com vocabul√°rio extenso, j√° que a possibilidade de erro aumenta geometricamente (para cada palavra adicionada, s√£o n compara√ß√µes a mais) necessitando de mais indiv√≠duos e mais gera√ß√µes, diminuindo muito a efici√™ncia computacional.

# üìΩÔ∏è V√≠deo de Apresenta√ß√£o
